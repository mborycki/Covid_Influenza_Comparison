{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid and Influenza - sick and death cases comparison\n",
    "\n",
    "**Part 1 - Cleaning / Transforming data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In here I am going to check how the influenza detected cases has been changed after covid19 pandemic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sources:**\n",
    "- Covid19: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data\n",
    "\n",
    "\n",
    "- Influenza: https://flunewseurope.org/VirusCharacteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Covid19 source - Terms of Use:**\n",
    "1.\tThis data set is licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) by the Johns Hopkins University on behalf of its Center for Systems Science in Engineering. Copyright Johns Hopkins University 2020.\n",
    "2.\tAttribute the data as the \"COVID-19 Data Repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University\" or \"JHU CSSE COVID-19 Data\" for short, and the url: https://github.com/CSSEGISandData/COVID-19.\n",
    "3.\tFor publications that use the data, please cite the following publication: \"Dong E, Du H, Gardner L. An interactive web-based dashboard to track COVID-19 in real time. Lancet Inf Dis. 20(5):533-534. doi: 10.1016/S1473-3099(20)30120-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re \n",
    "import io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Influenza\n",
    "Let's start from Influenza virus detections by type in Europe\n",
    "\n",
    "## A1. Extract Data\n",
    "All data have been downloaded from [here](https://flunewseurope.org/VirusCharacteristics). I have filtered by all countries and all dates from the list. I transfered it to my github repository just after I have downloaded it as .xlsx from the website page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_flu = \"https://raw.githubusercontent.com/mborycki/Covid_Influenza_Comparison/main/Influenza_virus_detections_in_Europe.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected = pd.read_csv(url_flu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2. Transform / Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected['Region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected[(flu_detected.Country=='Poland')&(flu_detected.Week=='2015-W40')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flu_detected[(flu_detected.Country=='Poland')&(flu_detected.Region=='EU/EEA')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flu_detected[(flu_detected.Country=='Poland')&(flu_detected.Region=='WHO Europe')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected[(flu_detected.Country=='Poland')&(flu_detected.Region=='WHO Europe')].iloc[:,5:].values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected[(flu_detected.Country=='Poland')&(flu_detected.Region=='EU/EEA')].iloc[:,5:].values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flu_detected[flu_detected.Region=='EU/EEA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"In EEA we have {len(flu_detected[flu_detected.Region=='EU/EEA'])} records while in WHO Europe we have\"\n",
    "      f\" {len(flu_detected[flu_detected.Region=='WHO Europe'])} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected = flu_detected[flu_detected.Region == 'WHO Europe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First conclusion:**\n",
    "- Change coumn name: YearWeek - Week\n",
    "- What is \"Surveillance System Type\" and do we need it?\n",
    "- Do we need \"Season\" and \"Region\" columns? If not then remove them\n",
    "- Create total cases for flu\n",
    "- Unpivot the table\n",
    "- Split YearWeek column into 2 separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected.rename(columns={'Week':'YearWeek'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected['Surveillance System Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected['Season'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected['YearWeek'].unique()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, I do not need columns \"Surveillance System Type\" (_one unique value: 'Non-sentinel'_), \"Season\" (_Week is more precise_) and \"Region\" (_only 'WHO Europe'_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this column is just in one table. So I did not have it in the above function\n",
    "flu_detected = flu_detected.drop(['Season','Region','Surveillance System Type'],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected.iloc[:,2:].head(2) # we will summarize it from the third column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a total flu detected cases\n",
    "flu_detected['Total Detected Cases'] = flu_detected.iloc[:,2:].sum(axis=1).values\n",
    "flu_detected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected[(flu_detected['Total Detected Cases']>0)&(flu_detected.YearWeek=='2021-W01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected[(flu_detected.Country=='Poland')&(flu_detected.YearWeek=='2016-W04')] # looks ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpivot table \n",
    "def FluPivot(df,colname):\n",
    "    x = pd.melt(df, id_vars=['Country', 'YearWeek'], var_name='Flu Type', value_name='Cases').sort_values(['YearWeek','Country'])\n",
    "    x[['Year', 'Week']] = x['YearWeek'].str.split('-', n=1, expand=True)\n",
    "    x = x.drop([\"YearWeek\"],axis=1)\n",
    "    x.rename(columns={'Cases':colname},inplace=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2 = FluPivot(flu_detected,'Detected_Cases')\n",
    "flu_detected2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2['Flu Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2[(flu_detected2.Country=='Poland')&(flu_detected2.Year=='2016')\\\n",
    "              &(flu_detected2['Flu Type']=='Total Detected Cases')]['Detected_Cases'].sum() # looks ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2[(flu_detected2.Country=='Poland')&(flu_detected2.Year=='2016')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Flu Type names\n",
    "original_type_names = ['A not subtyped', 'A(H1)pdm09', 'A(H3)',\n",
    "       'B lineage not determined', 'B/Vic', 'B/Yam']\n",
    "\n",
    "new_type_names = ['A', 'A(H1)', 'A(H3)','B', 'B/Vic', 'B/Yam']\n",
    "\n",
    "for o, n in zip(original_type_names,new_type_names):\n",
    "    flu_detected2.loc[(flu_detected2['Flu Type'] == o),'Flu Type']=n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2['Flu Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount od total cases\n",
    "flu_detected2[(flu_detected2['Flu Type']=='Total Detected Cases')].sort_values(['Year']).groupby(['Flu Type','Year'])\\\n",
    "['Detected_Cases'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount of records\n",
    "flu_detected2[(flu_detected2['Flu Type']=='Total Detected Cases')].groupby('Year')['Flu Type'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = flu_detected2.Year.unique()\n",
    "for year in years:\n",
    "    print(f'In {year} we have {len(flu_detected2[flu_detected2.Year==year].Week.unique())} weeks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecesary weeks\n",
    "years_list = ['2016','2017','2018','2019','2020', '2021'] # we keep 2021 as covid data are available for this year\n",
    "flu_detected2 = flu_detected2[flu_detected2['Year'].isin(years_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = flu_detected2[flu_detected2['Flu Type']!='Total Detected Cases'].groupby(['Flu Type', 'Year'])['Detected_Cases'].sum().reset_index()\n",
    "df2 = df1.pivot(index=\"Year\", columns=\"Flu Type\", values=\"Detected_Cases\").reset_index().set_index('Year')\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.rcParams[\"figure.figsize\"] = (25,15)\n",
    "plt.xticks(fontsize=16, rotation=45)\n",
    "plt.grid(color='grey', linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "width = 0.8\n",
    "bottom = 0\n",
    "\n",
    "for i in df2.columns:\n",
    "    plt.bar(df2.index, df2[i], width=width, bottom=bottom)\n",
    "    bottom += df2[i]\n",
    "\n",
    "plt.title(f\"Influenza Cases per year in Europe\", fontsize=28)\n",
    "plt.xlabel('Years', fontsize=24)\n",
    "plt.ylabel(\"Detected Flu Cases\", color='black', fontsize=24)\n",
    "plt.tick_params(axis='y', labelcolor='black', labelsize=16) \n",
    "plt.legend(df2.columns, fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2[(flu_detected2.Country=='Poland')&(flu_detected2['Flu Type']=='Total Detected Cases')].sort_values(['Year'])\\\n",
    ".groupby(['Flu Type','Year'])['Detected_Cases'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Remove all Flu Types except the totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu = flu_detected2[(flu_detected2['Flu Type']=='Total Detected Cases')].sort_values(['Year'])\\\n",
    ".groupby(['Country','Year', 'Week'])['Detected_Cases'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_flu.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.groupby('Year')['Detected_Cases'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# total for all countries\n",
    "xs = df_flu.groupby('Year')['Detected_Cases'].sum().reset_index()['Year']\n",
    "ys = df_flu.groupby('Year')['Detected_Cases'].sum().reset_index().Detected_Cases.values\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "plt.plot(xs,ys,'bo-')\n",
    "plt.title(f'Total influenza cases for all countries', fontsize=24)\n",
    "\n",
    "for x,y in zip(xs,ys):\n",
    "\n",
    "    #label = \"{:.0f}\".format(y)\n",
    "    label = f'{y:,}'\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (x,y), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "plt.grid(color = 'green', linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total for chosen country\n",
    "country = 'Poland'\n",
    "xs = df_flu[df_flu.Country==country].groupby('Year')['Detected_Cases'].sum().reset_index()['Year']\n",
    "ys = df_flu[df_flu.Country==country].groupby('Year')['Detected_Cases'].sum().reset_index().Detected_Cases.values\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "plt.plot(xs,ys,'bo-')\n",
    "plt.title(f'Total influenza cases in {country}', fontsize=24)\n",
    "\n",
    "for x,y in zip(xs,ys):\n",
    "\n",
    "    #label = \"{:.0f}\".format(y)\n",
    "    label = f'{y:,}'\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (x,y), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "plt.grid(color = 'green', linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu['Week'] = df_flu['Week'].map(lambda x: x.lstrip('W'))\n",
    "df_flu['Week'] = df_flu['Week'].astype('int')\n",
    "df_flu['Year'] = df_flu['Year'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.sort_values(['Year','Week']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu[(df_flu.Country=='Poland')].sort_values(['Year'])\\\n",
    ".groupby(['Year'])['Detected_Cases'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table with influenza data seems to be clean and ready to use. Now, let's check the covid table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Covid19\n",
    "\n",
    "## B1. Scrape Data\n",
    "Please find all details arond the report in the [Daily reports (csse_covid_19_daily_reports)](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports)\n",
    "This folder contains daily case reports. All timestamps are in UTC (GMT+0).\n",
    "\n",
    "In the report, there is many different columns but we will use just some of them:\n",
    "\n",
    "---\n",
    "**Field description**\n",
    "* <b>Country_Region</b>: Country, region or sovereignty name. The names of locations included on the Website correspond with the official designations used by the U.S. Department of State.\n",
    "* <b>Last Update</b>: MM/DD/YYYY HH:mm:ss  (24 hour format, in UTC).\n",
    "* <b>Lat</b> and <b>Long_</b>: Dot locations on the dashboard. All points (except for Australia) shown on the map are based on geographic centroids, and are not representative of a specific address, building or any location at a spatial scale finer than a province/state. Australian dots are located at the centroid of the largest city in each state.\n",
    "* <b>Confirmed</b>: Counts include confirmed and probable (where reported).\n",
    "* <b>Deaths</b>: Counts include confirmed and probable (where reported).\n",
    "* <b>Recovered</b>: Recovered cases are estimates based on local media reports, and state and local reporting when available, and therefore may be substantially lower than the true number. US state-level recovered cases are from [COVID Tracking Project](https://covidtracking.com/).\n",
    "* <b>File_Name</b>: It is a column created by me contain the name of the .csv file with data (in a date format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports\"\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = r.text\n",
    "soup = BeautifulSoup(html_doc)\n",
    "a_tags = soup.find_all('a')\n",
    "\n",
    "# Store a list of urls ending in .csv: urls => list\n",
    "urls = ['https://raw.githubusercontent.com'+re.sub('/blob', '', link.get('href'))\n",
    "        for link in a_tags if '.csv' in link.get('href')]\n",
    "\n",
    "# Store a list of Data Frame names to be assigned to the list: df_list_names => list\n",
    "df_list_names = [url.split('.csv')[0].split('/')[url.count('/')] for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.DataFrame(columns=['File_Name','Added','Not_Added'])\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Country_Region','Last_Update','Lat','Long_','Confirmed','Deaths','Recovered','File_Name']\n",
    "\n",
    "covid_table = pd.DataFrame(columns = cols)\n",
    "covid_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add_Comment(url_name, is_ok, is_not_ok):\n",
    "    data = [[url_name,is_ok,is_not_ok]]\n",
    "    comment_note = pd.DataFrame(data, columns = ['File_Name','Added','Not_Added'])\n",
    "    return comment_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some tables have a bit different column names, if so then I keep only the below names\n",
    "col_names1 = ['Country_Region','Last_Update','Lat','Long_','Confirmed','Deaths','Recovered']\n",
    "col_names2 = ['Country/Region','Last Update','Latitude','Longitude','Confirmed','Deaths','Recovered']\n",
    "col_names3 = ['Country/Region','Last Update','Confirmed','Deaths','Recovered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, url in enumerate(urls):\n",
    "    download = requests.get(url).content\n",
    "    # Reading the downloaded content and turning it into a pandas dataframe\n",
    "    df = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
    "    if (df.shape[1] == 14) | (df.shape[1] == 12):\n",
    "        df = df[col_names1]\n",
    "    elif df.shape[1] == 8:\n",
    "        df = df[col_names2]\n",
    "    elif df.shape[1] == 6:\n",
    "        df = df[col_names3]\n",
    "        df['Lat'] = 0\n",
    "        df['Long_'] = 0\n",
    "        df = df[['Country/Region','Last Update','Lat','Long_','Confirmed','Deaths','Recovered']]\n",
    "    else:\n",
    "        print(f'We have {df.shape[1]} columns in {url} file')\n",
    "    \n",
    "    df['File_Name'] = df_list_names[count]        \n",
    "    try:\n",
    "        df.columns = cols # renaming the columns\n",
    "        covid_table = covid_table.append(df, ignore_index=True)\n",
    "        comment = Add_Comment(df_list_names[count], 1, 0)\n",
    "        comments = comments.append(comment, ignore_index=True)\n",
    "    except:\n",
    "        comment = Add_Comment(df_list_names[count], 0, 1)\n",
    "        comments = comments.append(comment, ignore_index=True)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if there is any file I did not download\n",
    "comments[['Added','Not_Added']].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B2. Transform / Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid = covid_table.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing format for 2 columns with dates\n",
    "df_covid['File_Name'] = pd.to_datetime(df_covid['File_Name']).dt.date\n",
    "df_covid['Last_Update'] = pd.to_datetime(df_covid['Last_Update']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.fillna({'Deaths':0,'Confirmed':0,'Recovered':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_cases_list = ['Confirmed','Deaths','Recovered']\n",
    "for case in covid_cases_list:\n",
    "    df_covid[case] = df_covid[case].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_covid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid = df_covid.groupby(['Country_Region','Last_Update']).agg({'Confirmed':'sum','Deaths':'sum','Recovered':'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting week/year as numbers\n",
    "week_no = []\n",
    "year_no = []\n",
    "for value in df_covid['Last_Update']:\n",
    "    week_no.append(value.isocalendar()[1])\n",
    "    year_no.append(value.isocalendar()[0])\n",
    "\n",
    "df_covid['Week'] = week_no\n",
    "df_covid['Year'] = year_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid[(df_covid.Country_Region=='Poland')&(df_covid.Week==20)&(df_covid.Year==2021)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid = df_covid.groupby(['Country_Region','Week','Year'], sort=False).agg({'Confirmed':'max','Deaths':'max','Recovered':'max'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid[(df_covid.Country_Region=='Poland')&(df_covid.Week==20)&(df_covid.Year==2021)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid[(df_covid.Country_Region=='Poland')]['Confirmed'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.Year.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the table look quite well. Now I am going to combine the table with Influenza table\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Tables\n",
    "We need to keep all outputs in one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.rename(columns={'Country_Region':'Country'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First tables correlations need to be check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlations seems to be ok. Now, I have concerns whether the countries have the same names in both tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_countries = df_flu[['Country']].drop_duplicates()\n",
    "flu_countries['flu'] = 1\n",
    "cov_countries = df_covid[['Country']].drop_duplicates()\n",
    "cov_countries['cov'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.merge(flu_countries,cov_countries,on='Country',how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries[countries['cov'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see countries names which are different in both tables. Of course the names need to be the same in both tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_countries = ['Herzego','Koso','Mold','Mace','Turkm','Kingdom']\n",
    "print('Covid:')\n",
    "for c in missing_countries:\n",
    "    print(df_covid[df_covid.Country.str.contains(c)].Country.unique()) #flu_df2\n",
    "    \n",
    "print('\\nInfluenza:')\n",
    "for c in missing_countries:\n",
    "    print(df_flu[df_flu.Country.str.contains(c)].Country.unique()) #flu_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_countries = ['Herzego','Koso','Mold','Mace','Kingdom', 'Rus']\n",
    "new_countries = ['Bosnia and Herzegovina','Kosovo','Moldova','Macedonia','United Kingdom', 'Russia'] \n",
    "\n",
    "for old,new in zip(missing_countries,new_countries):\n",
    "    df_covid.loc[df_covid.Country.str.contains(old), 'Country'] = new\n",
    "    df_flu.loc[df_flu.Country.str.contains(old), 'Country'] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covid:')\n",
    "for c in missing_countries:\n",
    "    print(df_covid[df_covid.Country.str.contains(c)].Country.unique()) #flu_df2\n",
    "    \n",
    "print('\\nInfluenza:')\n",
    "for c in missing_countries:\n",
    "    print(df_flu[df_flu.Country.str.contains(c)].Country.unique()) #flu_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the coutries names are the same (Turkmenistan is missing in Covid table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.rename(columns={'Detected_Cases':'Detected_FluCases'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_flu should be default table\n",
    "final_df = pd.merge(df_covid,df_flu,on=['Country','Year','Week'],how='right').sort_values(['Year','Week','Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[(final_df.Year==2021) & (final_df.Confirmed.isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems everything is ok so we can change NaN into 0 for covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.fillna({'Deaths':0,'Confirmed':0,'Recovered':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.Week.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarters = pd.DataFrame(columns={\"Week\",\"Quarter\"})\n",
    "def quarter(x): \n",
    "    if (x <= 13):\n",
    "        return 1\n",
    "    elif (x <= 26):\n",
    "        return 2\n",
    "    elif (x <= 39):\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "quarters['Week'] = final_df.Week.unique()\n",
    "quarters['Quarter'] = quarters['Week'].apply(quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.merge(quarters,on='Week',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.Quarter.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show me the countries where influenza were detected in this year\n",
    "final_df[(final_df.Detected_FluCases>0)&(final_df.Year==2021)].sort_values('Detected_FluCases',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I have compared the number of confirmed covid cases with the covid map (to be sure my data are proper)\n",
    "final_df[(final_df.Country=='Poland')]['Confirmed'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top level table checking and saving the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('Covid_and_Influenza.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
