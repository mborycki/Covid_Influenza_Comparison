{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid and Influenza - sick and death cases comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sources:**\n",
    "- https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data\n",
    "- https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset\n",
    "- https://flunewseurope.org/VirusCharacteristics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Terms of Use:**\n",
    "1.\tThis data set is licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) by the Johns Hopkins University on behalf of its Center for Systems Science in Engineering. Copyright Johns Hopkins University 2020.\n",
    "2.\tAttribute the data as the \"COVID-19 Data Repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University\" or \"JHU CSSE COVID-19 Data\" for short, and the url: https://github.com/CSSEGISandData/COVID-19.\n",
    "3.\tFor publications that use the data, please cite the following publication: \"Dong E, Du H, Gardner L. An interactive web-based dashboard to track COVID-19 in real time. Lancet Inf Dis. 20(5):533-534. doi: 10.1016/S1473-3099(20)30120-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "\n",
    "**Influenza:**\n",
    "- Add a description - where I found flu reports\n",
    "- “Influenza virus detections by type in Europe.xlsx”\n",
    "\n",
    "**Covid:** Use csv files from csse_covid_19_time_series folder\n",
    "- refresh this report: (https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data) and add README - description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re \n",
    "import io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.dirname(os.path.abspath(\"__file__\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_flue = os.path.join(BASE_DIR, 'influenza')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Influenza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "Influenza virus detections by type in Europe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = 'Influenza virus detections by type in Europe.xlsx'\n",
    "flu_detected = pd.read_excel(os.path.join(directory_flue, ws).replace('\\\\','/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected['Region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected[(flu_detected.Country=='Poland')&(flu_detected.Week=='2015-W40')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flu_detected[(flu_detected.Country=='Poland')&(flu_detected.Region=='EU/EEA')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flu_detected[(flu_detected.Country=='Poland')&(flu_detected.Region=='WHO Europe')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected[(flu_detected.Country=='Poland')&(flu_detected.Region=='WHO Europe')].iloc[:,5:].values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected[(flu_detected.Country=='Poland')&(flu_detected.Region=='EU/EEA')].iloc[:,5:].values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flu_detected[flu_detected.Region=='EU/EEA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"In EEA we have {len(flu_detected[flu_detected.Region=='EU/EEA'])} records while in WHO Europe we have\"\n",
    "      f\" {len(flu_detected[flu_detected.Region=='WHO Europe'])} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected = flu_detected[flu_detected.Region == 'WHO Europe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First conclusion:\n",
    "- Both tables looks similar\n",
    "- Change coumn name: YearWeek - Week\n",
    "- What is \"Surveillance System Type\" and do we need it?\n",
    "- Do we need \"Season\" and \"Region\" columns? If not then remove them\n",
    "- Create total cases for flu\n",
    "- Unpivot the table\n",
    "- Split YearWeek column into 2 separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected.rename(columns={'Week':'YearWeek'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected['Surveillance System Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected['Season'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected['YearWeek'].unique()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, I do not need columns \"Surveillance System Type\" (_one unique value: 'Non-sentinel'_), \"Season\" (_Week is more precise_) and \"Region\" (_only 'WHO Europe'_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "Now I will create 2 functions:\n",
    "1. Calculate total influenza cases\n",
    "2. Unpivot a table to keep it simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this column is just in one table. So I did not have it in the above function\n",
    "flu_detected = flu_detected.drop(['Season','Region','Surveillance System Type'],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected['Total Detected Cases'] = flu_detected.iloc[:,4:].sum(axis=1).values\n",
    "flu_detected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected[(flu_detected['Total Detected Cases']>0)&(flu_detected.YearWeek=='2021-W01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpivot table \n",
    "def FluPivot(df,colname):\n",
    "    x = pd.melt(df, id_vars=['Country', 'YearWeek'], var_name='Flu Type', value_name='Cases').sort_values(['YearWeek','Country'])\n",
    "    x[['Year', 'Week']] = x['YearWeek'].str.split('-', n=1, expand=True)\n",
    "    x = x.drop([\"YearWeek\"],axis=1)\n",
    "    x.rename(columns={'Cases':colname},inplace=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2 = FluPivot(flu_detected,'Detected_Cases')\n",
    "flu_detected2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2['Flu Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Flu Type names\n",
    "original_type_names = ['A not subtyped', 'A(H1)pdm09', 'A(H3)',\n",
    "       'B lineage not determined', 'B/Vic', 'B/Yam']\n",
    "\n",
    "new_type_names = ['A', 'A(H1)', 'A(H3)','B', 'B/Vic', 'B/Yam']\n",
    "\n",
    "for o, n in zip(original_type_names,new_type_names):\n",
    "    flu_detected2.loc[(flu_detected2['Flu Type'] == o),'Flu Type']=n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in (flu_detected2.Year.unique()):\n",
    "    print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for year in (flu_detected2.Year.unique()):\n",
    "    fd2 = flu_detected2[(flu_detected2.Year==year)&(flu_detected2['Flu Type']!='Total Detected Cases')].groupby(['Flu Type'])['Detected_Cases'].sum().sort_values().reset_index()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    types = fd2['Flu Type']\n",
    "    cases = fd2.Detected_Cases\n",
    "    result = ax.bar(types,cases)\n",
    "\n",
    "    ax.set_ylabel('Total Cases')\n",
    "    ax.set_xlabel('Flu Types')\n",
    "    ax.set_title(f'Detected Influenza Cases per type - {year}')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount od total cases\n",
    "flu_detected2[(flu_detected2['Flu Type']=='Total Detected Cases')].sort_values(['Year']).groupby(['Flu Type','Year'])\\\n",
    "['Detected_Cases'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount of records\n",
    "flu_detected2[(flu_detected2['Flu Type']=='Total Detected Cases')].groupby('Year')['Flu Type'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = flu_detected2.Year.unique()\n",
    "for year in years:\n",
    "    print(f'In {year} we have {len(flu_detected2[flu_detected2.Year==year].Week.unique())} weeks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecesary weeks\n",
    "# flu_detected2 = flu_detected2[flu_detected2.Year!='2015']\n",
    "years_list = ['2016','2017','2018','2019','2020', '2021'] # we keep 2021 as covid data are available for this year\n",
    "flu_detected2 = flu_detected2[flu_detected2['Year'].isin(years_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd2 = flu_detected2[(flu_detected2['Flu Type']=='Total Detected Cases')].sort_values(['Year'])\\\n",
    ".groupby(['Flu Type','Year'])['Detected_Cases'].sum().reset_index()\n",
    "\n",
    "xs = fd2['Year']\n",
    "ys = fd2.Detected_Cases.values\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "plt.plot(xs,ys,'bo-')\n",
    "\n",
    "for x,y in zip(xs,ys):\n",
    "\n",
    "    #label = \"{:.0f}\".format(y)\n",
    "    label = f'{y:,}'\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (x,y), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "plt.grid(color = 'green', linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu = flu_detected2.groupby(['Country','Year','Week'])['Detected_Cases'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.sort_values(['Year','Week']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Import Covid tables down below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Daily reports (csse_covid_19_daily_reports)](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports)\n",
    "\n",
    "This folder contains daily case reports. All timestamps are in UTC (GMT+0).\n",
    "\n",
    "### File naming convention\n",
    "MM-DD-YYYY.csv in UTC.\n",
    "\n",
    "### Field description\n",
    "* <b>FIPS</b>: US only. Federal Information Processing Standards code that uniquely identifies counties within the USA.\n",
    "* <b>Admin2</b>: County name. US only.\n",
    "* <b>Province_State</b>: Province, state or dependency name.\n",
    "* <b>Country_Region</b>: Country, region or sovereignty name. The names of locations included on the Website correspond with the official designations used by the U.S. Department of State.\n",
    "* <b>Last Update</b>: MM/DD/YYYY HH:mm:ss  (24 hour format, in UTC).\n",
    "* <b>Lat</b> and <b>Long_</b>: Dot locations on the dashboard. All points (except for Australia) shown on the map are based on geographic centroids, and are not representative of a specific address, building or any location at a spatial scale finer than a province/state. Australian dots are located at the centroid of the largest city in each state.\n",
    "* <b>Confirmed</b>: Counts include confirmed and probable (where reported).\n",
    "* <b>Deaths</b>: Counts include confirmed and probable (where reported).\n",
    "* <b>Recovered</b>: Recovered cases are estimates based on local media reports, and state and local reporting when available, and therefore may be substantially lower than the true number. US state-level recovered cases are from [COVID Tracking Project](https://covidtracking.com/).\n",
    "* <b>Active:</b> Active cases = total cases - total recovered - total deaths.\n",
    "* <b>Incident_Rate</b>: Incidence Rate = cases per 100,000 persons.\n",
    "* <b>Case_Fatality_Ratio (%)</b>: Case-Fatality Ratio (%) = Number recorded deaths / Number cases.\n",
    "* All cases, deaths, and recoveries reported are based on the date of initial report. Exceptions to this are noted in the \"Data Modification\" and \"Retrospective reporting of (probable) cases and deaths\" subsections below.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we need:\n",
    "\n",
    "* <b>Country_Region</b>: Country, region or sovereignty name. The names of locations included on the Website correspond with the official designations used by the U.S. Department of State.\n",
    "* <b>Last Update</b>: MM/DD/YYYY HH:mm:ss  (24 hour format, in UTC).\n",
    "* <b>Lat</b> and <b>Long_</b>: Dot locations on the dashboard. All points (except for Australia) shown on the map are based on geographic centroids, and are not representative of a specific address, building or any location at a spatial scale finer than a province/state. Australian dots are located at the centroid of the largest city in each state.\n",
    "* <b>Confirmed</b>: Counts include confirmed and probable (where reported).\n",
    "* <b>Deaths</b>: Counts include confirmed and probable (where reported).\n",
    "* <b>Recovered</b>: Recovered cases are estimates based on local media reports, and state and local reporting when available, and therefore may be substantially lower than the true number. US state-level recovered cases are from [COVID Tracking Project](https://covidtracking.com/).\n",
    "* <b>Active:</b> Active cases = total cases - total recovered - total deaths.\n",
    "* <b>Incident_Rate</b>: Incidence Rate = cases per 100,000 persons.\n",
    "* <b>Case_Fatality_Ratio (%)</b>: Case-Fatality Ratio (%) = Number recorded deaths / Number cases.\n",
    "* All cases, deaths, and recoveries reported are based on the date of initial report. Exceptions to this are noted in the \"Data Modification\" and \"Retrospective reporting of (probable) cases and deaths\" subsections below.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports\"\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = r.text\n",
    "soup = BeautifulSoup(html_doc)\n",
    "a_tags = soup.find_all('a')\n",
    "\n",
    "# Store a list of urls ending in .csv: urls => list\n",
    "urls = ['https://raw.githubusercontent.com'+re.sub('/blob', '', link.get('href'))\n",
    "        for link in a_tags  if '.csv' in link.get('href')]\n",
    "\n",
    "# Store a list of Data Frame names to be assigned to the list: df_list_names => list\n",
    "df_list_names = [url.split('.csv')[0].split('/')[url.count('/')] for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.DataFrame(columns=['File_Name','Added','Not_Added'])\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Country_Region','Last_Update','Lat','Long_','Confirmed','Deaths','Recovered','File_Name']\n",
    "\n",
    "covid_table = pd.DataFrame(columns = cols)\n",
    "covid_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add_Comment(url_name, is_ok, is_not_ok):\n",
    "    data = [[url_name,is_ok,is_not_ok]]\n",
    "    comment_note = pd.DataFrame(data, columns = ['File_Name','Added','Not_Added'])\n",
    "    return comment_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some tables have a bit different column names, if so then I keep only the below names\n",
    "col_names1 = ['Country_Region','Last_Update','Lat','Long_','Confirmed','Deaths','Recovered']\n",
    "col_names2 = ['Country/Region','Last Update','Latitude','Longitude','Confirmed','Deaths','Recovered']\n",
    "col_names3 = ['Country/Region','Last Update','Confirmed','Deaths','Recovered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, url in enumerate(urls):\n",
    "    download = requests.get(url).content\n",
    "    # Reading the downloaded content and turning it into a pandas dataframe\n",
    "    df = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
    "    if (df.shape[1] == 14) | (df.shape[1] == 12):\n",
    "        df = df[col_names1]\n",
    "    elif df.shape[1] == 8:\n",
    "        df = df[col_names2]\n",
    "    elif df.shape[1] == 6:\n",
    "        df = df[col_names3]\n",
    "        df['Lat'] = 0\n",
    "        df['Long_'] = 0\n",
    "        df = df[['Country/Region','Last Update','Lat','Long_','Confirmed','Deaths','Recovered']]\n",
    "    else:\n",
    "        print(f'We have {df.shape[1]} columns in {url} file')\n",
    "    \n",
    "    df['File_Name'] = df_list_names[count]        \n",
    "    try:\n",
    "        df.columns = cols # renaming the columns\n",
    "        covid_table = covid_table.append(df, ignore_index=True)\n",
    "        comment = Add_Comment(df_list_names[count], 1, 0)\n",
    "        comments = comments.append(comment, ignore_index=True)\n",
    "    except:\n",
    "        comment = Add_Comment(df_list_names[count], 0, 1)\n",
    "        comments = comments.append(comment, ignore_index=True)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments[['Added','Not_Added']].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the file\n",
    "to safe my time for loading data from the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_table.to_csv('covid_summary.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid = pd.read_csv('covid_summary.csv')\n",
    "# df_covid = covid_table.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covid Table Analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['File_Name'] = pd.to_datetime(df_covid['File_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['Last_Update'] = pd.to_datetime(df_covid['Last_Update']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_covid['Recovered'] = df_covid['Recovered'].replace('', np.nan)\n",
    "# df_covid['Deaths'] = df_covid['Deaths'].replace('', np.nan)\n",
    "# df_covid['Confirmed'] = df_covid['Confirmed'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.fillna({'Deaths':0,'Confirmed':0,'Recovered':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['Confirmed'] = df_covid['Confirmed'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['Recovered'] = df_covid['Recovered'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['Deaths'] = df_covid['Deaths'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting week/year as numbers\n",
    "week_no = []\n",
    "year_no = []\n",
    "for value in df_covid['Last_Update']:\n",
    "    week_no.append(value.isocalendar()[1])\n",
    "    year_no.append(value.isocalendar()[0])\n",
    "\n",
    "df_covid['Week'] = week_no\n",
    "df_covid['Year'] = year_no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Startpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In here change the function!!! We cannot summarize everyday? Double check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid[(df_covid.Country_Region=='Germany')&(df_covid.File_Name=='2021-05-22')]['Confirmed'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid[(df_covid.Country_Region=='Germany')&(df_covid.File_Name=='2021-05-23')]['Confirmed'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid[(df_covid.Country_Region=='Germany')&(df_covid.File_Name=='2021-05-24')]['Confirmed'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid[(df_covid.Country_Region=='Germany')&(df_covid.File_Name=='2021-05-23')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will try to do a sum for Week (current way)\n",
    "df_covid.loc[(df_covid.Country_Region=='Germany')&(df_covid.Week==21)&(df_covid.Year==2021),('File_Name','Last_Update','Week',\n",
    "'Year','Confirmed', 'Deaths','Recovered')].groupby(['Week']).sum().reset_index()\n",
    "\n",
    "# THIS IS WHAT I DID BUT IT IS WRONG!!! IT SHOULD BE ~3MLN NOT 7!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will try to do a sum for File_Name\n",
    "df_covid.loc[(df_covid.Country_Region=='Germany')&(df_covid.Week==21)&(df_covid.Year==2021),('File_Name','Last_Update','Week',\n",
    "'Year','Confirmed', 'Deaths','Recovered')].groupby(['File_Name']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will try to do a sum for Last_Update\n",
    "df_covid.loc[(df_covid.Country_Region=='Germany')&(df_covid.Week==21)&(df_covid.Year==2021),('File_Name','Last_Update','Week',\n",
    "'Year','Confirmed', 'Deaths','Recovered')].groupby(['Last_Update']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid = pd.read_csv('covid_summary.csv')\n",
    "df_covid['File_Name'] = pd.to_datetime(df_covid['File_Name']).dt.date\n",
    "df_covid['Last_Update'] = pd.to_datetime(df_covid['Last_Update']).dt.date\n",
    "\n",
    "df_covid.fillna({'Deaths':0,'Confirmed':0,'Recovered':0},inplace=True)\n",
    "df_covid['Confirmed'] = df_covid['Confirmed'].astype(float)\n",
    "df_covid['Deaths'] = df_covid['Deaths'].astype(float)\n",
    "df_covid['Recovered'] = df_covid['Recovered'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid = df_covid.groupby(['Country_Region','Last_Update']).agg({'Confirmed':'sum','Deaths':'sum','Recovered':'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting week/year as numbers\n",
    "week_no = []\n",
    "year_no = []\n",
    "for value in df_covid['Last_Update']:\n",
    "    week_no.append(value.isocalendar()[1])\n",
    "    year_no.append(value.isocalendar()[0])\n",
    "\n",
    "df_covid['Week'] = week_no\n",
    "df_covid['Year'] = year_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid[(df_covid.Country_Region=='Germany')&(df_covid.Week==21)&(df_covid.Year==2021)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid[(df_covid.Country_Region=='Germany')&(df_covid.Year==2021)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid[(df_covid.Country_Region=='Germany')&(df_covid.Year==2021)].groupby(['Week'], sort=False).agg({'Confirmed':'max','Deaths':'max','Recovered':'max'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid = df_covid.groupby(['Country_Region','Week','Year'], sort=False).agg({'Confirmed':'max','Deaths':'max','Recovered':'max'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid[(df_covid.Country_Region=='Germany')&(df_covid.Week==21)&(df_covid.Year==2021)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid = df_covid.groupby(['Country_Region','Week','Year']).agg({'Confirmed':'sum','Deaths':'sum','Recovered':'sum'}).reset_index().sort_values(['Country_Region','Week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.Year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid[(df_covid.Country_Region=='Poland')&(df_covid.Year==2020)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covid_table_sum = covid_table[['Country_Region','Last_Update','Confirmed', 'Deaths','Recovered']]\n",
    "# covid_table_sum = covid_table_sum.groupby(['Country_Region','Last_Update']).agg({'Confirmed':'sum','Deaths':'sum','Recovered':'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.rename(columns={'Country_Region':'Country'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu['Week'] = df_flu['Week'].map(lambda x: x.lstrip('W'))\n",
    "df_flu['Week'] = df_flu['Week'].astype('int')\n",
    "df_flu['Year'] = df_flu['Year'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_countries = df_flu[['Country']].drop_duplicates()\n",
    "flu_countries['flu'] = 1\n",
    "cov_countries = df_covid[['Country']].drop_duplicates()\n",
    "cov_countries['cov'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.merge(flu_countries,cov_countries,on='Country',how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries[countries['cov'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Now we can see countries names which are different in both tables. I am going to change them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_countries = ['Herzego','Koso','Mold','Mace','Turkm','Kingdom']\n",
    "print('Covid:')\n",
    "for c in missing_countries:\n",
    "    print(df_covid[df_covid.Country.str.contains(c)].Country.unique()) #flu_df2\n",
    "    \n",
    "print('\\nInfluenza:')\n",
    "for c in missing_countries:\n",
    "    print(df_flu[df_flu.Country.str.contains(c)].Country.unique()) #flu_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_countries = ['Herzego','Koso','Mold','Mace','Kingdom', 'Rus']\n",
    "new_countries = ['Bosnia and Herzegovina','Kosovo','Moldova','Macedonia','United Kingdom', 'Russia'] \n",
    "\n",
    "for old,new in zip(missing_countries,new_countries):\n",
    "    df_covid.loc[df_covid.Country.str.contains(old), 'Country'] = new\n",
    "    df_flu.loc[df_flu.Country.str.contains(old), 'Country'] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covid:')\n",
    "for c in missing_countries:\n",
    "    print(df_covid[df_covid.Country.str.contains(c)].Country.unique()) #flu_df2\n",
    "    \n",
    "print('\\nInfluenza:')\n",
    "for c in missing_countries:\n",
    "    print(df_flu[df_flu.Country.str.contains(c)].Country.unique()) #flu_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the coutries names are the same (Turkmenistan is missing in Covid table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.rename(columns={'Detected_Cases':'Detected_FluCases'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(df_covid,df_flu,on=['Country','Year','Week'],how='right').sort_values(['Year','Week','Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[(final_df.Year==2021) & (final_df.Confirmed.isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems everything is ok so we can change NaN into 0 for covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.fillna({'Deaths':0,'Confirmed':0,'Recovered':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.Week.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {\n",
    "#   \"Week\": [1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
    "#        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
    "#        35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
    "#        52, 53],\n",
    "#   \"Quarter\": [1,  1,  1,  1,  1,  6,  7,  8,  9, 10, 11, 12, 1, 2, 15, 16, 17,\n",
    "#        18, 19, 20, 21, 22, 23, 24, 25, 26, 3, 28, 29, 30, 31, 32, 33, 34,\n",
    "#        35, 36, 37, 38, 39, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 452, 53]\n",
    "# }\n",
    "\n",
    "# quarters = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarters = pd.DataFrame(columns={\"Week\",\"Quarter\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarter(x): \n",
    "    if (x <= 13):\n",
    "        return 1\n",
    "    elif (x <= 26):\n",
    "        return 2\n",
    "    elif (x <= 39):\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "quarters['Week'] = final_df.Week.unique()\n",
    "quarters['Quarter'] = quarters['Week'].apply(quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.merge(quarters,on='Week',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.Quarter.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[(final_df.Detected_FluCases>0)&(final_df.Year==2021)].sort_values('Detected_FluCases',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['Country', 'Year', 'Confirmed', 'Deaths', 'Recovered',\n",
    "       'Detected_FluCases', 'Quarter']].groupby(['Year','Quarter']).sum().sort_values(['Year','Quarter']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quarter 2 is not finished yet\n",
    "final_df.drop(final_df[(final_df.Quarter==2)&(final_df.Year==2021)].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_grouped = final_df[['Country', 'Year', 'Confirmed', 'Deaths', 'Recovered',\n",
    "       'Detected_FluCases', 'Quarter']].groupby(['Year','Quarter']).sum().sort_values(['Year','Quarter']).reset_index()\n",
    "final_df_grouped.rename(columns={ 'Confirmed':'Confirmed_(mln)', 'Deaths':'Deaths_(mln)', 'Recovered':'Recovered_(mln)'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collist = ['Confirmed_(mln)','Deaths_(mln)','Recovered_(mln)']\n",
    "for col in collist:\n",
    "    for value in range(len(final_df_grouped)):\n",
    "        final_df_grouped.loc[value,(col)] = final_df_grouped.loc[value,(col)] / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in the covid_df table we need to rename countries from this list: countries[countries['cov'].isnull()] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dodaj ponizej porownanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chart = final_df_grouped.copy()\n",
    "chart['YearQuater'] = chart.Year.astype(str)+'-Q'+chart.Quarter.astype(str)\n",
    "chart = chart.drop([\"Year\",\"Quarter\"],axis=1)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.xticks(fontsize=16, rotation=45)\n",
    "\n",
    "y = chart['Confirmed_(mln)']\n",
    "x = chart.YearQuater.unique()\n",
    "z = chart.Detected_FluCases\n",
    "\n",
    "ax1.set_title(f'Confirmed Covid Cases per week', fontsize=24)\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Periods', fontsize=20)\n",
    "ax1.set_ylabel('Confirmed Covid19 Cases (mln)', color=color, fontsize=20)\n",
    "ax1.plot(x, y, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color, labelsize = 16)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Detected Inluenza Cases', color=color, fontsize=20)  # we already handled the x-label with ax1\n",
    "ax2.plot(x, z, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color, labelsize = 16)\n",
    "\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid[df_covid.Country_Region=='Germany'].sort_values(['Year','Week'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
