{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid and Influenza - sick and death cases comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sources:**\n",
    "- https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data\n",
    "- https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset\n",
    "- https://flunewseurope.org/VirusCharacteristics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Terms of Use:**\n",
    "1.\tThis data set is licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) by the Johns Hopkins University on behalf of its Center for Systems Science in Engineering. Copyright Johns Hopkins University 2020.\n",
    "2.\tAttribute the data as the \"COVID-19 Data Repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University\" or \"JHU CSSE COVID-19 Data\" for short, and the url: https://github.com/CSSEGISandData/COVID-19.\n",
    "3.\tFor publications that use the data, please cite the following publication: \"Dong E, Du H, Gardner L. An interactive web-based dashboard to track COVID-19 in real time. Lancet Inf Dis. 20(5):533-534. doi: 10.1016/S1473-3099(20)30120-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "\n",
    "**Influenza:**\n",
    "- Add a description - where I found flu reports\n",
    "- “Influenza virus detections by type in Europe.xlsx”\n",
    "\n",
    "**Covid:** Use csv files from csse_covid_19_time_series folder\n",
    "- refresh this report: (https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data) and add README - description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re \n",
    "import io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.dirname(os.path.abspath(\"__file__\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_flue = os.path.join(BASE_DIR, 'influenza')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Influenza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "Influenza virus detections by type in Europe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = 'Influenza virus detections by type in Europe.xlsx'\n",
    "flu_detected = pd.read_excel(os.path.join(directory_flue, ws).replace('\\\\','/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected['Region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected[(flu_detected.Country=='Poland')&(flu_detected.Week=='2015-W40')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flu_detected[(flu_detected.Country=='Poland')&(flu_detected.Region=='EU/EEA')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flu_detected[(flu_detected.Country=='Poland')&(flu_detected.Region=='WHO Europe')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected[(flu_detected.Country=='Poland')&(flu_detected.Region=='WHO Europe')].iloc[:,5:].values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected[(flu_detected.Country=='Poland')&(flu_detected.Region=='EU/EEA')].iloc[:,5:].values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flu_detected[flu_detected.Region=='EU/EEA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"In EEA we have {len(flu_detected[flu_detected.Region=='EU/EEA'])} records while in WHO Europe we have\"\n",
    "      f\" {len(flu_detected[flu_detected.Region=='WHO Europe'])} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected = flu_detected[flu_detected.Region == 'WHO Europe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First conclusion:\n",
    "- Both tables looks similar\n",
    "- Change coumn name: YearWeek - Week\n",
    "- What is \"Surveillance System Type\" and do we need it?\n",
    "- Do we need \"Season\" and \"Region\" columns? If not then remove them\n",
    "- Create total cases for flu\n",
    "- Unpivot the table\n",
    "- Split YearWeek column into 2 separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected.rename(columns={'Week':'YearWeek'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected['Surveillance System Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected['Season'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected['YearWeek'].unique()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, I do not need columns \"Surveillance System Type\" (_one unique value: 'Non-sentinel'_), \"Season\" (_Week is more precise_) and \"Region\" (_only 'WHO Europe'_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "Now I will create 2 functions:\n",
    "1. Calculate total influenza cases\n",
    "2. Unpivot a table to keep it simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this column is just in one table. So I did not have it in the above function\n",
    "flu_detected = flu_detected.drop(['Season','Region','Surveillance System Type'],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected['Total Detected Cases'] = flu_detected.iloc[:,4:].sum(axis=1).values\n",
    "flu_detected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected[(flu_detected['Total Detected Cases']>0)&(flu_detected.YearWeek=='2021-W01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpivot table \n",
    "def FluPivot(df,colname):\n",
    "    x = pd.melt(df, id_vars=['Country', 'YearWeek'], var_name='Flu Type', value_name='Cases').sort_values(['YearWeek','Country'])\n",
    "    x[['Year', 'Week']] = x['YearWeek'].str.split('-', n=1, expand=True)\n",
    "    x = x.drop([\"YearWeek\"],axis=1)\n",
    "    x.rename(columns={'Cases':colname},inplace=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2 = FluPivot(flu_detected,'Detected_Cases')\n",
    "flu_detected2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2['Flu Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Flu Type names\n",
    "original_type_names = ['A not subtyped', 'A(H1)pdm09', 'A(H3)',\n",
    "       'B lineage not determined', 'B/Vic', 'B/Yam']\n",
    "\n",
    "new_type_names = ['A', 'A(H1)', 'A(H3)','B', 'B/Vic', 'B/Yam']\n",
    "\n",
    "for o, n in zip(original_type_names,new_type_names):\n",
    "    flu_detected2.loc[(flu_detected2['Flu Type'] == o),'Flu Type']=n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in (flu_detected2.Year.unique()):\n",
    "    print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for year in (flu_detected2.Year.unique()):\n",
    "    fd2 = flu_detected2[(flu_detected2.Year==year)&(flu_detected2['Flu Type']!='Total Detected Cases')].groupby(['Flu Type'])['Detected_Cases'].sum().sort_values().reset_index()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    types = fd2['Flu Type']\n",
    "    cases = fd2.Detected_Cases\n",
    "    result = ax.bar(types,cases)\n",
    "\n",
    "    ax.set_ylabel('Total Cases')\n",
    "    ax.set_xlabel('Flu Types')\n",
    "    ax.set_title(f'Detected Influenza Cases per type - {year}')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount od total cases\n",
    "flu_detected2[(flu_detected2['Flu Type']=='Total Detected Cases')].sort_values(['Year']).groupby(['Flu Type','Year'])\\\n",
    "['Detected_Cases'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount of records\n",
    "flu_detected2[(flu_detected2['Flu Type']=='Total Detected Cases')].groupby('Year')['Flu Type'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = flu_detected2.Year.unique()\n",
    "for year in years:\n",
    "    print(f'In {year} we have {len(flu_detected2[flu_detected2.Year==year].Week.unique())} weeks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecesary weeks\n",
    "# flu_detected2 = flu_detected2[flu_detected2.Year!='2015']\n",
    "years_list = ['2016','2017','2018','2019','2020', '2021'] # we keep 2021 as covid data are available for this year\n",
    "flu_detected2 = flu_detected2[flu_detected2['Year'].isin(years_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd2 = flu_detected2[(flu_detected2['Flu Type']=='Total Detected Cases')].sort_values(['Year'])\\\n",
    ".groupby(['Flu Type','Year'])['Detected_Cases'].sum().reset_index()\n",
    "\n",
    "xs = fd2['Year']\n",
    "ys = fd2.Detected_Cases.values\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "plt.plot(xs,ys,'bo-')\n",
    "\n",
    "for x,y in zip(xs,ys):\n",
    "\n",
    "    #label = \"{:.0f}\".format(y)\n",
    "    label = f'{y:,}'\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (x,y), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "plt.grid(color = 'green', linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_detected2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu = flu_detected2.groupby(['Country','Year','Week'])['Detected_Cases'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flu.sort_values(['Year','Week']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Import Covid tables down below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Daily reports (csse_covid_19_daily_reports)](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports)\n",
    "\n",
    "This folder contains daily case reports. All timestamps are in UTC (GMT+0).\n",
    "\n",
    "### File naming convention\n",
    "MM-DD-YYYY.csv in UTC.\n",
    "\n",
    "### Field description\n",
    "* <b>FIPS</b>: US only. Federal Information Processing Standards code that uniquely identifies counties within the USA.\n",
    "* <b>Admin2</b>: County name. US only.\n",
    "* <b>Province_State</b>: Province, state or dependency name.\n",
    "* <b>Country_Region</b>: Country, region or sovereignty name. The names of locations included on the Website correspond with the official designations used by the U.S. Department of State.\n",
    "* <b>Last Update</b>: MM/DD/YYYY HH:mm:ss  (24 hour format, in UTC).\n",
    "* <b>Lat</b> and <b>Long_</b>: Dot locations on the dashboard. All points (except for Australia) shown on the map are based on geographic centroids, and are not representative of a specific address, building or any location at a spatial scale finer than a province/state. Australian dots are located at the centroid of the largest city in each state.\n",
    "* <b>Confirmed</b>: Counts include confirmed and probable (where reported).\n",
    "* <b>Deaths</b>: Counts include confirmed and probable (where reported).\n",
    "* <b>Recovered</b>: Recovered cases are estimates based on local media reports, and state and local reporting when available, and therefore may be substantially lower than the true number. US state-level recovered cases are from [COVID Tracking Project](https://covidtracking.com/).\n",
    "* <b>Active:</b> Active cases = total cases - total recovered - total deaths.\n",
    "* <b>Incident_Rate</b>: Incidence Rate = cases per 100,000 persons.\n",
    "* <b>Case_Fatality_Ratio (%)</b>: Case-Fatality Ratio (%) = Number recorded deaths / Number cases.\n",
    "* All cases, deaths, and recoveries reported are based on the date of initial report. Exceptions to this are noted in the \"Data Modification\" and \"Retrospective reporting of (probable) cases and deaths\" subsections below.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we need:\n",
    "\n",
    "* <b>Country_Region</b>: Country, region or sovereignty name. The names of locations included on the Website correspond with the official designations used by the U.S. Department of State.\n",
    "* <b>Last Update</b>: MM/DD/YYYY HH:mm:ss  (24 hour format, in UTC).\n",
    "* <b>Lat</b> and <b>Long_</b>: Dot locations on the dashboard. All points (except for Australia) shown on the map are based on geographic centroids, and are not representative of a specific address, building or any location at a spatial scale finer than a province/state. Australian dots are located at the centroid of the largest city in each state.\n",
    "* <b>Confirmed</b>: Counts include confirmed and probable (where reported).\n",
    "* <b>Deaths</b>: Counts include confirmed and probable (where reported).\n",
    "* <b>Recovered</b>: Recovered cases are estimates based on local media reports, and state and local reporting when available, and therefore may be substantially lower than the true number. US state-level recovered cases are from [COVID Tracking Project](https://covidtracking.com/).\n",
    "* <b>Active:</b> Active cases = total cases - total recovered - total deaths.\n",
    "* <b>Incident_Rate</b>: Incidence Rate = cases per 100,000 persons.\n",
    "* <b>Case_Fatality_Ratio (%)</b>: Case-Fatality Ratio (%) = Number recorded deaths / Number cases.\n",
    "* All cases, deaths, and recoveries reported are based on the date of initial report. Exceptions to this are noted in the \"Data Modification\" and \"Retrospective reporting of (probable) cases and deaths\" subsections below.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports\"\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_doc = r.text\n",
    "soup = BeautifulSoup(html_doc)\n",
    "a_tags = soup.find_all('a')\n",
    "\n",
    "# Store a list of urls ending in .csv: urls => list\n",
    "urls = ['https://raw.githubusercontent.com'+re.sub('/blob', '', link.get('href'))\n",
    "        for link in a_tags  if '.csv' in link.get('href')]\n",
    "\n",
    "# Store a list of Data Frame names to be assigned to the list: df_list_names => list\n",
    "df_list_names = [url.split('.csv')[0].split('/')[url.count('/')] for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-01-2021.csv',\n",
       " 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-02-2021.csv',\n",
       " 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-03-2021.csv',\n",
       " 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-04-2021.csv',\n",
       " 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-05-2021.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01-01-2021', '01-02-2021', '01-03-2021', '01-04-2021', '01-05-2021']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Added</th>\n",
       "      <th>Not_Added</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [File_Name, Added, Not_Added]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = pd.DataFrame(columns=['File_Name','Added','Not_Added'])\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>File_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Country_Region, Last_Update, Lat, Long_, Confirmed, Deaths, Recovered, File_Name]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Country_Region','Last_Update','Lat','Long_','Confirmed','Deaths','Recovered','File_Name']\n",
    "\n",
    "covid_table = pd.DataFrame(columns = cols)\n",
    "covid_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add_Comment(url_name, is_ok, is_not_ok):\n",
    "    data = [[url_name,is_ok,is_not_ok]]\n",
    "    comment_note = pd.DataFrame(data, columns = ['File_Name','Added','Not_Added'])\n",
    "    return comment_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some tables have a bit different column names, if so then I keep only the below names\n",
    "col_names1 = ['Country_Region','Last_Update','Lat','Long_','Confirmed','Deaths','Recovered']\n",
    "col_names2 = ['Country/Region','Last Update','Latitude','Longitude','Confirmed','Deaths','Recovered']\n",
    "col_names3 = ['Country/Region','Last Update','Confirmed','Deaths','Recovered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, url in enumerate(urls):\n",
    "    download = requests.get(url).content\n",
    "    # Reading the downloaded content and turning it into a pandas dataframe\n",
    "    df = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
    "    if (df.shape[1] == 14) | (df.shape[1] == 12):\n",
    "        df = df[col_names1]\n",
    "    elif df.shape[1] == 8:\n",
    "        df = df[col_names2]\n",
    "    elif df.shape[1] == 6:\n",
    "        df = df[col_names3]\n",
    "        df['Lat'] = 0\n",
    "        df['Long_'] = 0\n",
    "        df = df[['Country/Region','Last Update','Lat','Long_','Confirmed','Deaths','Recovered']]\n",
    "    else:\n",
    "        print(f'We have {df.shape[1]} columns in {url} file')\n",
    "    \n",
    "    df['File_Name'] = df_list_names[count]        \n",
    "    try:\n",
    "        df.columns = cols # renaming the columns\n",
    "        covid_table = covid_table.append(df, ignore_index=True)\n",
    "        comment = Add_Comment(df_list_names[count], 1, 0)\n",
    "        comments = comments.append(comment, ignore_index=True)\n",
    "    except:\n",
    "        comment = Add_Comment(df_list_names[count], 0, 1)\n",
    "        comments = comments.append(comment, ignore_index=True)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>File_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2021-01-01 05:23:07</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>51526</td>\n",
       "      <td>2191</td>\n",
       "      <td>41727</td>\n",
       "      <td>12-31-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2021-01-01 05:23:07</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>58316</td>\n",
       "      <td>1181</td>\n",
       "      <td>33634</td>\n",
       "      <td>12-31-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2021-01-01 05:23:07</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>99610</td>\n",
       "      <td>2756</td>\n",
       "      <td>67127</td>\n",
       "      <td>12-31-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>2021-01-01 05:23:07</td>\n",
       "      <td>42.50630</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>8049</td>\n",
       "      <td>84</td>\n",
       "      <td>7432</td>\n",
       "      <td>12-31-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>2021-01-01 05:23:07</td>\n",
       "      <td>-11.20270</td>\n",
       "      <td>17.873900</td>\n",
       "      <td>17553</td>\n",
       "      <td>405</td>\n",
       "      <td>11044</td>\n",
       "      <td>12-31-2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country_Region          Last_Update       Lat      Long_  Confirmed  Deaths  \\\n",
       "0    Afghanistan  2021-01-01 05:23:07  33.93911  67.709953      51526    2191   \n",
       "1        Albania  2021-01-01 05:23:07  41.15330  20.168300      58316    1181   \n",
       "2        Algeria  2021-01-01 05:23:07  28.03390   1.659600      99610    2756   \n",
       "3        Andorra  2021-01-01 05:23:07  42.50630   1.521800       8049      84   \n",
       "4         Angola  2021-01-01 05:23:07 -11.20270  17.873900      17553     405   \n",
       "\n",
       "   Recovered   File_Name  \n",
       "0      41727  12-31-2020  \n",
       "1      33634  12-31-2020  \n",
       "2      67127  12-31-2020  \n",
       "3       7432  12-31-2020  \n",
       "4      11044  12-31-2020  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>File_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2021-01-02 05:22:33</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>51526</td>\n",
       "      <td>2191</td>\n",
       "      <td>41727</td>\n",
       "      <td>01-01-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2021-01-02 05:22:33</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>58316</td>\n",
       "      <td>1181</td>\n",
       "      <td>33634</td>\n",
       "      <td>01-01-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2021-01-02 05:22:33</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>99897</td>\n",
       "      <td>2762</td>\n",
       "      <td>67395</td>\n",
       "      <td>01-01-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>2021-01-02 05:22:33</td>\n",
       "      <td>42.50630</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>8117</td>\n",
       "      <td>84</td>\n",
       "      <td>7463</td>\n",
       "      <td>01-01-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>2021-01-02 05:22:33</td>\n",
       "      <td>-11.20270</td>\n",
       "      <td>17.873900</td>\n",
       "      <td>17568</td>\n",
       "      <td>405</td>\n",
       "      <td>11146</td>\n",
       "      <td>01-01-2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country_Region          Last_Update       Lat      Long_ Confirmed Deaths  \\\n",
       "0    Afghanistan  2021-01-02 05:22:33  33.93911  67.709953     51526   2191   \n",
       "1        Albania  2021-01-02 05:22:33  41.15330  20.168300     58316   1181   \n",
       "2        Algeria  2021-01-02 05:22:33  28.03390   1.659600     99897   2762   \n",
       "3        Andorra  2021-01-02 05:22:33  42.50630   1.521800      8117     84   \n",
       "4         Angola  2021-01-02 05:22:33 -11.20270  17.873900     17568    405   \n",
       "\n",
       "  Recovered   File_Name  \n",
       "0     41727  01-01-2021  \n",
       "1     33634  01-01-2021  \n",
       "2     67395  01-01-2021  \n",
       "3      7463  01-01-2021  \n",
       "4     11146  01-01-2021  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1645514 entries, 0 to 1645513\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   Country_Region  1645514 non-null  object \n",
      " 1   Last_Update     1645514 non-null  object \n",
      " 2   Lat             1611454 non-null  float64\n",
      " 3   Long_           1611454 non-null  float64\n",
      " 4   Confirmed       1645485 non-null  object \n",
      " 5   Deaths          1645072 non-null  object \n",
      " 6   Recovered       1386287 non-null  object \n",
      " 7   File_Name       1645514 non-null  object \n",
      "dtypes: float64(2), object(6)\n",
      "memory usage: 100.4+ MB\n"
     ]
    }
   ],
   "source": [
    "covid_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments[['Added','Not_Added']].sum().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the file\n",
    "to safe my time for loading data from the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_table.to_csv('covid_summary.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid = pd.read_csv('covid_summary.csv')\n",
    "# df_covid = covid_table.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covid Table Analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['File_Name'] = pd.to_datetime(df_covid['File_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['Last_Update'] = pd.to_datetime(df_covid['Last_Update']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_covid['Recovered'] = df_covid['Recovered'].replace('', np.nan)\n",
    "# df_covid['Deaths'] = df_covid['Deaths'].replace('', np.nan)\n",
    "# df_covid['Confirmed'] = df_covid['Confirmed'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.fillna({'Deaths':0,'Confirmed':0,'Recovered':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['Confirmed'] = df_covid['Confirmed'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['Recovered'] = df_covid['Recovered'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['Deaths'] = df_covid['Deaths'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last update shows date the data come from but to vompare it with flue we need to get week number.\n",
    "# To get week number we will use isocalendar function\n",
    "week_no = []\n",
    "year_no = []\n",
    "for value in df_covid['Last_Update']:\n",
    "    week_no.append(value.isocalendar()[1])\n",
    "    year_no.append(value.isocalendar()[0])\n",
    "\n",
    "df_covid['Week'] = week_no\n",
    "df_covid['Year'] = year_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid = df_covid.groupby(['Country_Region','Week','Year']).agg({'Confirmed':'sum','Deaths':'sum','Recovered':'sum'}).reset_index().sort_values(['Country_Region','Week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid[(df_covid.Country_Region=='Poland')&(df_covid.Year==2020)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.Year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covid_table_sum = covid_table[['Country_Region','Last_Update','Confirmed', 'Deaths','Recovered']]\n",
    "# covid_table_sum = covid_table_sum.groupby(['Country_Region','Last_Update']).agg({'Confirmed':'sum','Deaths':'sum','Recovered':'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.rename(columns={'Country_Region':'Country'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_df2['Week'] = flu_df2['Week'].map(lambda x: x.lstrip('W'))\n",
    "flu_df2['Week'] = flu_df2['Week'].astype('int')\n",
    "flu_df2['Year'] = flu_df2['Year'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_countries = flu_df2[['Country']].drop_duplicates()\n",
    "flu_countries['flu'] = 1\n",
    "cov_countries = covid_df[['Country']].drop_duplicates()\n",
    "cov_countries['cov'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.merge(flu_countries,cov_countries,on='Country',how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries[countries['cov'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Now we can see countries names which are different in both tables. I am going to change them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_countries = ['Herzego','Koso','Mold','Mace','Turkm','Kingdom']\n",
    "print('Covid:')\n",
    "for c in missing_countries:\n",
    "    print(covid_df[covid_df.Country.str.contains(c)].Country.unique()) #flu_df2\n",
    "    \n",
    "print('\\nInfluenza:')\n",
    "for c in missing_countries:\n",
    "    print(flu_df2[flu_df2.Country.str.contains(c)].Country.unique()) #flu_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_countries = ['Herzego','Koso','Mold','Mace','Kingdom', 'Rus']\n",
    "new_countries = ['Bosnia and Herzegovina','Kosovo','Moldova','Macedonia','United Kingdom', 'Russia'] # in covid_df we have Russian Federation\n",
    "\n",
    "for old,new in zip(missing_countries,new_countries):\n",
    "    covid_df.loc[covid_df.Country.str.contains(old), 'Country'] = new\n",
    "    flu_df2.loc[flu_df2.Country.str.contains(old), 'Country'] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covid:')\n",
    "for c in missing_countries:\n",
    "    print(covid_df[covid_df.Country.str.contains(c)].Country.unique()) #flu_df2\n",
    "    \n",
    "print('\\nInfluenza:')\n",
    "for c in missing_countries:\n",
    "    print(flu_df2[flu_df2.Country.str.contains(c)].Country.unique()) #flu_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the coutries names are the same (Turkmenistan is missing in Covid table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_df2.rename(columns={'Detected_Cases':'Detected_FluCases', 'Hospitalized_Cases':'Hospitalized_FluCases'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(covid_df,flu_df2,on=['Country','Year','Week'],how='right').sort_values(['Year','Week','Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[(final_df.Year==2021) & (final_df.Confirmed.isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[(final_df.Year==2020) & (final_df.Confirmed.isnull())]['Week'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems everything is ok so we can change NaN into 0 for covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.fillna({'Deaths':0,'Confirmed':0,'Recovered':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.Week.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  \"Week\": [1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
    "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
    "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
    "       52, 53],\n",
    "  \"Quarter\": [1,  1,  1,  1,  1,  6,  7,  8,  9, 10, 11, 12, 1, 2, 15, 16, 17,\n",
    "       18, 19, 20, 21, 22, 23, 24, 25, 26, 3, 28, 29, 30, 31, 32, 33, 34,\n",
    "       35, 36, 37, 38, 39, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 452, 53]\n",
    "}\n",
    "\n",
    "quarters = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarters = pd.DataFrame(columns={\"Week\",\"Quarter\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarter(x): \n",
    "    if (x <= 13):\n",
    "        return 1\n",
    "    elif (x <= 26):\n",
    "        return 2\n",
    "    elif (x <= 39):\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "quarters['Week'] = final_df.Week.unique()\n",
    "quarters['Quarter'] = quarters['Week'].apply(quarter)\n",
    "quarters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.merge(quarters,on='Week',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[(final_df.Detected_FluCases>0)&(final_df.Year==2021)].sort_values('Detected_FluCases',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[final_df.Country=='Poland',('Country', 'Year', 'Confirmed', 'Deaths', 'Recovered',\n",
    "       'Detected_FluCases', 'Hospitalized_FluCases', 'Quarter')].groupby(['Year','Quarter']).sum().sort_values(['Year','Quarter']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Steps:\n",
    "\n",
    "- Remove Quarter2 2021\n",
    "- check why we do not have any Flu in 2021 (download it if we do not have)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in the covid_df table we need to rename countries from this list: countries[countries['cov'].isnull()] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dodaj ponizej porownanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = final_df.copy()\n",
    "chart['YearQuater'] = chart.Year.astype(str)+'-'+chart.Quarter.astype(str)\n",
    "chart = chart.groupby(['YearQuater']).agg({'Confirmed':'sum','Deaths':'sum','Recovered':'sum','Detected_FluCases':'sum','Hospitalized_FluCases':'sum'}).reset_index()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "\n",
    "y = chart.Confirmed\n",
    "x = chart.YearQuater.unique()\n",
    "\n",
    "result = ax.plot(x,y)\n",
    "\n",
    "\n",
    "# # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Confirmed Cases')\n",
    "ax.set_xlabel('Periods')\n",
    "ax.set_title(f'Confirmed Covid Cases per week')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
